"""
tests/test_elk_client.py
Test ELK Client - Fetch pfSense firewall logs vÃ  lÆ°u vÃ o file JSONL

Chá»©c nÄƒng:
- --once: Fetch 1000 logs má»›i nháº¥t má»™t láº§n â†’ hiá»ƒn thá»‹ thá»‘ng kÃª + lÆ°u file
- --stream: Realtime streaming â†’ má»—i batch má»›i nháº­n Ä‘Æ°á»£c sáº½ append vÃ o file
- File lÆ°u: data/raw/elk_logs.jsonl (JSON Lines format)
- CÃ³ __main__ Ä‘á»ƒ cháº¡y trá»±c tiáº¿p
"""

import argparse
import json
import os
import sys
from datetime import datetime

import yaml

from src.integrations.elk_client import check_connection, fetch_logs_realtime
from src.utils.logger import get_module_logger

logger = get_module_logger("TestELKClient")

# =================== LOAD CONFIG Äá»‚ Láº¤Y ÄÆ¯á»œNG DáºªN LÆ¯U FILE ===================
CONFIG_PATH = "config/config.yaml"

def load_log_file_path() -> str:
    if not os.path.exists(CONFIG_PATH):
        logger.error(f"âŒ KhÃ´ng tÃ¬m tháº¥y file config: {CONFIG_PATH}")
        sys.exit(1)

    with open(CONFIG_PATH, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    log_path = config.get('data', {}).get('elk_logs')
    if not log_path:
        logger.error("âŒ KhÃ´ng tÃ¬m tháº¥y 'data.elk_logs' trong config.yaml")
        sys.exit(1)

    # Äáº£m báº£o pháº§n má»Ÿ rá»™ng lÃ  .jsonl
    if not log_path.endswith('.jsonl'):
        log_path = log_path.rstrip('/') + '.jsonl'

    # Táº¡o thÆ° má»¥c náº¿u chÆ°a tá»“n táº¡i
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    return log_path

ELK_LOGS_PATH = load_log_file_path()


def append_logs_to_file(logs: list[dict]):
    """Append batch logs vÃ o file JSONL (má»—i log má»™t dÃ²ng)"""
    if not logs:
        return

    try:
        with open(ELK_LOGS_PATH, 'a', encoding='utf-8') as f:
            for log in logs:
                json.dump(log, f, ensure_ascii=False)
                f.write('\n')
        logger.info(f"ğŸ’¾ ÄÃ£ append {len(logs)} logs vÃ o {ELK_LOGS_PATH}")
    except Exception as e:
        logger.error(f"âŒ Lá»—i ghi file logs: {e}")


def test_once():
    """Test fetch má»™t láº§n duy nháº¥t - láº¥y 1000 logs má»›i nháº¥t vÃ  lÆ°u file"""
    logger.info("ğŸ§ª Cháº¿ Ä‘á»™ TEST ONCE - Fetch 1000 logs má»›i nháº¥t")

    if not check_connection():
        sys.exit(1)

    # Táº¡o generator vá»›i batch_size lá»›n hÆ¡n Ä‘á»ƒ láº¥y initial batch 1000 logs
    stream_gen = fetch_logs_realtime(batch_size=500, interval=10)

    try:
        # Láº§n next Ä‘áº§u tiÃªn sáº½ tráº£ vá» batch initial 1000 logs má»›i nháº¥t
        batch_logs = next(stream_gen)
        logger.success(f"âœ… Fetch thÃ nh cÃ´ng {len(batch_logs)} logs má»›i nháº¥t")

        # LÆ°u vÃ o file JSONL
        append_logs_to_file(batch_logs)

        print("\n" + "â•" * 100)
        print("                  ğŸ“Š 1000 LOGS FIREWALL Má»šI NHáº¤T (Ä‘Ã£ lÆ°u file)")
        print("â•" * 100)
        print(f"   ğŸ“ File lÆ°u: {ELK_LOGS_PATH}")
        print("â•" * 100 + "\n")

    except StopIteration:
        logger.warning("âš ï¸ KhÃ´ng cÃ³ logs nÃ o Ä‘á»ƒ fetch")
    except Exception as e:
        logger.error(f"âŒ Lá»—i khi fetch: {e}")
        sys.exit(1)


def test_stream(batch_size: int = 500, interval: int = 20):
    """Test realtime streaming - liÃªn tá»¥c fetch vÃ  append vÃ o file"""
    logger.success("ğŸš€ Cháº¿ Ä‘á»™ REALTIME STREAMING - Theo dÃµi + lÆ°u logs liÃªn tá»¥c")
    logger.info(f"   Batch size (sau initial): {batch_size}")
    logger.info(f"   Interval: {interval}s")
    logger.info(f"   Initial batch: 1000 logs má»›i nháº¥t")
    logger.info(f"   Logs sáº½ Ä‘Æ°á»£c append vÃ o: {ELK_LOGS_PATH}")
    logger.info("   Nháº¥n Ctrl+C Ä‘á»ƒ dá»«ng\n")

    if not check_connection():
        sys.exit(1)

    try:
        for batch_logs in fetch_logs_realtime(batch_size=batch_size, interval=interval):
            if batch_logs:
                # LÆ°u vÃ o file ngay khi nháº­n batch má»›i
                append_logs_to_file(batch_logs)

    except KeyboardInterrupt:
        logger.warning("\nâš ï¸ Dá»«ng streaming bá»Ÿi ngÆ°á»i dÃ¹ng (Ctrl+C)")
        logger.info("ğŸ‘‹ HoÃ n táº¥t! Logs Ä‘Ã£ Ä‘Æ°á»£c lÆ°u liÃªn tá»¥c.")
    except Exception as e:
        logger.error(f"âŒ Lá»—i nghiÃªm trá»ng trong streaming: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="ğŸ” Test ELK Client - Fetch & lÆ°u pfSense firewall logs tá»« Elasticsearch"
    )

    parser.add_argument(
        "-n", "--number",
        type=int,
        default=500,
        help="Batch size cho cÃ¡c láº§n fetch sau initial batch. Máº·c Ä‘á»‹nh: 500"
    )

    parser.add_argument(
        "-i", "--interval",
        type=int,
        default=20,
        help="Khoáº£ng thá»i gian giá»¯a cÃ¡c láº§n fetch (giÃ¢y) khi stream. Máº·c Ä‘á»‹nh: 20"
    )

    group = parser.add_mutually_exclusive_group()
    group.add_argument(
        "--once",
        action="store_true",
        help="Chá»‰ fetch má»™t láº§n (1000 logs má»›i nháº¥t) vÃ  lÆ°u file"
    )
    group.add_argument(
        "--stream",
        action="store_true",
        help="Cháº¡y realtime streaming vÃ  liÃªn tá»¥c append logs vÃ o file"
    )

    args = parser.parse_args()

    print(f"ğŸ• {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("â•" * 80)
    logger.info("ğŸ§ª Báº®T Äáº¦U TEST ELK CLIENT")
    print("â•" * 80 + "\n")

    if args.stream:
        test_stream(batch_size=args.number, interval=args.interval)
    else:
        # Náº¿u cÃ³ --once hoáº·c khÃ´ng cÃ³ option nÃ o â†’ cháº¡y cháº¿ Ä‘á»™ once
        if args.once:
            test_once()
        else:
            # Máº·c Ä‘á»‹nh váº«n lÃ  once Ä‘á»ƒ tÆ°Æ¡ng thÃ­ch hÃ nh vi cÅ©
            test_once()


if __name__ == "__main__":
    main()